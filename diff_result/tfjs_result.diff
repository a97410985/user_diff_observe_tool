diff --git a/a.js b/b.js
index ae7b8cabd..511c340e4 100644
--- a/a.js
+++ b/b.js
@@ -22,7 +22,7 @@
 
 let dirName = process.argv[2];
 if (dirName.endsWith('/')) {
-  dirName = dirName.substr(0, dirName.length - 1);
+  dirName = dirName.slice(0, -1);
 }
 const packageJsonFile = dirName + '/package.json';
 if (!fs.existsSync(packageJsonFile)) {
diff --git a/a.js b/b.js
index a9e146b1f..31c8dc397 100644
--- a/a.js
+++ b/b.js
@@ -40,7 +40,7 @@
 
 // Some windows machines contain a trailing " char:
 if (targetDir != undefined && targetDir.endsWith('"')) {
-  targetDir = targetDir.substr(0, targetDir.length - 1);
+  targetDir = targetDir.slice(0, -1);
 }
 
 // Setup dest binary paths:
diff --git a/a.js b/b.js
index 1f3591ca0..307830045 100644
--- a/a.js
+++ b/b.js
@@ -31,14 +31,7 @@ module.exports = function(env, argv) {
     },
     optimization: {
       minimizer: [
-        new TerserPlugin({
-          cache: true,
-          parallel: true,
-          sourceMap: false,
-          terserOptions: {
-            comments: false,
-          }
-        }),
+        new TerserPlugin({parallel: true, terserOptions: {}}),
       ]
     },
     module: {
diff --git a/a.js b/b.js
index 144070c34..3f042cdf1 100644
--- a/a.js
+++ b/b.js
@@ -6,7 +6,7 @@
     app: './src/index.js',
   },
   devServer: {
-    contentBase: './dist',
+    static: './dist',
   },
   plugins: [
     new HtmlWebpackPlugin({
diff --git a/a.js b/b.js
index 92b45eaff..302aa8a6e 100644
--- a/a.js
+++ b/b.js
@@ -22,8 +22,7 @@
 
 const GOOGLE_CLOUD_STORAGE_DIR =
     'https://storage.googleapis.com/tfjs-models/savedmodel/';
-const MODEL_URL =
-    GOOGLE_CLOUD_STORAGE_DIR + 'coco-ssd-mobilenet_v1/model.json';
+const MODEL_URL = GOOGLE_CLOUD_STORAGE_DIR + 'ssdlite_mobilenet_v2/model.json';
 
 let modelPromise;
 
@@ -48,33 +47,7 @@ button.onclick = () => {
   console.timeEnd('predict1');
   console.time('predict2');
   const res2 = await model.executeAsync(pixels.reshape([1, ...pixels.shape]));
-  const count = res2[3].dataSync()[0];
   const boxes = res2[0].dataSync();
   const scores = res2[1].dataSync();
-  const classes = res2[2].dataSync();
   console.timeEnd('predict2');
-
-
-  const c = document.getElementById('canvas');
-  const context = c.getContext('2d');
-  context.drawImage(image, 0, 0);
-  context.font = '10px Arial';
-
-  console.log('number of detections: ', count);
-  for (let i = 0; i < count; i++) {
-    const min_y = boxes[i * 4] * 399;
-    const min_x = boxes[i * 4 + 1] * 600;
-    const max_y = boxes[i * 4 + 2] * 399;
-    const max_x = boxes[i * 4 + 3] * 600;
-
-    context.beginPath();
-    context.rect(min_x, min_y, max_x - min_x, max_y - min_y);
-    context.lineWidth = 1;
-    context.strokeStyle = 'black';
-    context.stroke();
-    context.fillText(
-        scores[i].toFixed(3) + ' ' + CLASSES.find(label => label.id === classes[i]).display_name,
-        min_x, min_y - 5);
-  }
 };
-
diff --git a/a.js b/b.js
index 94d375d9e..3bdce1740 100644
--- a/a.js
+++ b/b.js
@@ -277,13 +277,22 @@ async function timeInference(predict, numRuns = 1) {
  */
 async function downloadValuesFromTensorContainer(tensorContainer) {
   let valueContainer;
+  const readSync = tf.getBackend() === 'webgl';
   if (tensorContainer instanceof tf.Tensor) {
-    valueContainer = await tensorContainer.data();
+    if (readSync) {
+      valueContainer = tensorContainer.dataSync();
+    } else {
+      valueContainer = await tensorContainer.data();
+    }
   } else if (Array.isArray(tensorContainer)) {
     // Start value downloads from all tensors.
     const valuePromiseContainer = tensorContainer.map(async item => {
       if (item instanceof tf.Tensor) {
-        return item.data();
+        if (readSync) {
+          return item.dataSync();
+        } else {
+          return item.data();
+        }
       }
       return item;
     });
@@ -294,7 +303,11 @@ async function downloadValuesFromTensorContainer(tensorContainer) {
     // Start value downloads from all tensors.
     for (const property in tensorContainer) {
       if (tensorContainer[property] instanceof tf.Tensor) {
-        valuePromiseContainer.push(tensorContainer[property].data());
+        if (readSync) {
+          valuePromiseContainer.push(tensorContainer[property].dataSync());
+        } else {
+          valuePromiseContainer.push(tensorContainer[property].data());
+        }
       } else {
         valuePromiseContainer.push(tensorContainer[property]);
       }
diff --git a/a.js b/b.js
index 817486335..0611d8f9a 100644
--- a/a.js
+++ b/b.js
@@ -16,6 +16,7 @@
  */
 
 const fs = require('fs');
+const http = require('http');
 const https = require('https');
 const HttpsProxyAgent = require('https-proxy-agent');
 const path = require('os').platform() === 'win32' ? require('path') :
@@ -36,6 +37,8 @@
  *     complete.
  */
 async function downloadAndUnpackResource(uri, destPath, callback) {
+  const httpClient = uri.startsWith('https') ? https : http;
+
   // If HTTPS_PROXY, https_proxy, HTTP_PROXY, or http_proxy is set
   const proxy = process.env['HTTPS_PROXY'] || process.env['https_proxy'] ||
       process.env['HTTP_PROXY'] || process.env['http_proxy'] || '';
@@ -44,13 +47,13 @@ async function downloadAndUnpackResource(uri, destPath, callback) {
   // http request.  the '...url.parse(targetUri)' part fills in the host,
   // path, protocol, etc from the targetUri and then we set the agent to the
   // default agent which is overridden a few lines down if there is a proxy
-  const options = {...url.parse(uri), agent: https.globalAgent};
+  const options = {...url.parse(uri), agent: httpClient.globalAgent};
 
   if (proxy !== '') {
     options.agent = new HttpsProxyAgent(proxy);
   }
 
-  const request = https.get(options, response => {
+  const request = httpClient.get(options, response => {
     const bar = new ProgressBar('[:bar] :rate/bps :percent :etas', {
       complete: '=',
       incomplete: ' ',
diff --git a/a.js b/b.js
index 3ab588d3b..3bdce1740 100644
--- a/a.js
+++ b/b.js
@@ -277,13 +277,22 @@ async function timeInference(predict, numRuns = 1) {
  */
 async function downloadValuesFromTensorContainer(tensorContainer) {
   let valueContainer;
+  const readSync = tf.getBackend() === 'webgl';
   if (tensorContainer instanceof tf.Tensor) {
-    valueContainer = await tensorContainer.data();
+    if (readSync) {
+      valueContainer = tensorContainer.dataSync();
+    } else {
+      valueContainer = await tensorContainer.data();
+    }
   } else if (Array.isArray(tensorContainer)) {
     // Start value downloads from all tensors.
     const valuePromiseContainer = tensorContainer.map(async item => {
       if (item instanceof tf.Tensor) {
-        return item.data();
+        if (readSync) {
+          return item.dataSync();
+        } else {
+          return item.data();
+        }
       }
       return item;
     });
@@ -294,7 +303,11 @@ async function downloadValuesFromTensorContainer(tensorContainer) {
     // Start value downloads from all tensors.
     for (const property in tensorContainer) {
       if (tensorContainer[property] instanceof tf.Tensor) {
-        valuePromiseContainer.push(tensorContainer[property].data());
+        if (readSync) {
+          valuePromiseContainer.push(tensorContainer[property].dataSync());
+        } else {
+          valuePromiseContainer.push(tensorContainer[property].data());
+        }
       } else {
         valuePromiseContainer.push(tensorContainer[property]);
       }
@@ -336,11 +349,13 @@ async function downloadValuesFromTensorContainer(tensorContainer) {
  *     memory usage in the inference process.
  * @param input The input tensor container for model inference.
  * @param isTflite Whether a TFLite model is being profiled or not.
+ * @param numProfiles The number of rounds for profiling the inference process.
  */
-async function profileModelInference(model, input, isTflite = false) {
+async function profileModelInference(
+    model, input, isTflite = false, numProfiles = 1) {
   const predict = isTflite ? () => tfliteModel.predict(input) :
                              getPredictFnForModel(model, input);
-  return profileInference(predict, isTflite);
+  return profileInference(predict, isTflite, numProfiles);
 }
 
 /**
@@ -372,8 +387,9 @@ async function profileModelInference(model, input, isTflite = false) {
  *
  * @param predict The predict function to execute for profiling memory usage.
  * @param isTflite Whether a TFLite model is being profiled or not.
+ * @param numProfiles The number of rounds for `predict` to execute and profile.
  */
-async function profileInference(predict, isTflite = false) {
+async function profileInference(predict, isTflite = false, numProfiles = 1) {
   if (typeof predict !== 'function') {
     throw new Error(
         'The first parameter should be a function, while ' +
@@ -381,24 +397,38 @@ async function profileInference(predict, isTflite = false) {
   }
 
   let kernelInfo = {};
+  let kernelInfos = [];
   if (isTflite) {
-    await predict();
-    const profileItems = tfliteModel.getProfilingResults();
-    kernelInfo.kernels = profileItems.map(item => {
-      return {
-        name: item.nodeType,
-        kernelTimeMs: item.nodeExecMs,
-        // TODO: Shapes are not supported yet.
-        inputShapes: [],
-        outputShapes: [],
-      };
-    });
+    for (let i = 0; i < numProfiles; i++) {
+      await predict();
+      const profileItems = tfliteModel.getProfilingResults();
+      kernelInfo.kernels = profileItems.map(item => {
+        return {
+          name: item.nodeType,
+          kernelTimeMs: item.nodeExecMs,
+          // TODO: Shapes are not supported yet.
+          inputShapes: [],
+          outputShapes: [],
+        };
+      });
+      kernelInfos.push(kernelInfo);
+    }
   } else {
-    kernelInfo = await tf.profile(async () => {
-      const res = await predict();
-      await downloadValuesFromTensorContainer(res);
-      tf.dispose(res);
-    });
+    for (let i = 0; i < numProfiles; i++) {
+      kernelInfo = await tf.profile(async () => {
+        const res = await predict();
+        await downloadValuesFromTensorContainer(res);
+        tf.dispose(res);
+      });
+      kernelInfos.push(kernelInfo);
+    }
+  }
+  for (let i = 0; i < kernelInfos[0].kernels.length; i++) {
+    let totalTimeMs = 0;
+    for (let j = 0; j < kernelInfos.length; j++) {
+      totalTimeMs += kernelInfos[j].kernels[i].kernelTimeMs;
+    }
+    kernelInfo.kernels[i].kernelTimeMs = totalTimeMs / kernelInfos.length;
   }
   kernelInfo.kernels =
       kernelInfo.kernels.sort((a, b) => b.kernelTimeMs - a.kernelTimeMs);
